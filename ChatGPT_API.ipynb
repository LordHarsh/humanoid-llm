{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPKGTVvJ8Gy88QCu1zNsF76",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LordHarsh/humanoid-llm/blob/lh%2Fgpt-api/ChatGPT_API.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O7fj9NSrITHR",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "id": "upPPfX_bLgyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title OPENAI API KEY { run: \"auto\", vertical-output: true, display-mode: \"both\" }\n",
        "\n",
        "#@markdown #### You can create a new API new a [OpenAI's official website](https://platform.openai.com/account/api-keyst)\n",
        "openai_api_key = \"\" #@param {type:\"string\"}\n",
        "if not openai_api_key:\n",
        "  raise Exception(\"Sorry, no api key provided\\n Create a new one at https://platform.openai.com/account/api-keyst\")\n",
        "openai.api_key = openai_api_key"
      ],
      "metadata": {
        "id": "EWcQcZUVvXxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def ask_gpt(prompt):\n",
        "#     response = openai.Completion.create(\n",
        "#         engine=\"gpt-3.5-turbo\",\n",
        "#         messages=prompt\n",
        "# #        max_tokens=1024,\n",
        "#         # n=1,\n",
        "#         # stop=None,\n",
        "#         # temperature=0.5,\n",
        "#     )\n",
        "\n",
        "#     message = response.choices[0].text.strip()\n",
        "#     return messagehttps://colab.research.google.com/drive/1H6fAAomocTLyMaLO2X0IQW7a2VFQc4xR?usp=sharingusp=sharing\n",
        "\n",
        "# prompt = \"I am an engineering professor. Can you help me with my lecture?\"\n",
        "# response = ask_gpt(prompt)\n",
        "# print(response)\n"
      ],
      "metadata": {
        "id": "0pxCAcgQJ71s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "p3S9OSVWrPSI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Chat:\n",
        "  def __init__(self):\n",
        "    self.history = [{\"role\": \"system\", \"content\": \"You are a helpful professor. You have deep knowledge about engineering and can answer related questions.\"}]\n",
        "  def ask(self, user_prompt):\n",
        "    self.history.append({\"role\": \"user\", \"content\": user_prompt})\n",
        "    gpt_response = self.ask_professor(self.history)\n",
        "    self.history.append({\"role\": \"assistant\", \"content\": gpt_response})\n",
        "    return gpt_response\n",
        "  def ask_professor(self, prompt):\n",
        "    completion = openai.ChatCompletion.create(\n",
        "      model=\"gpt-3.5-turbo\",\n",
        "      messages=prompt\n",
        "    )\n",
        "\n",
        "    return completion.choices[0].message.content.strip()\n"
      ],
      "metadata": {
        "id": "WZ85-KlVb90v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def create_promt(user_prompt, history=[]):\n",
        "#   if not history:\n",
        "#     prompt = [{\"role\": \"system\", \"content\": \"You are a helpful professor. You have deep knowledge about engineering and can answer related questions.\"}, {\"role\": \"user\", \"content\": user_prompt}]\n",
        "#     history = prompt.copy()"
      ],
      "metadata": {
        "id": "dJYPA49zcuY3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def simulate_chat():\n",
        "  user_chat = Chat()\n",
        "  user_prompt = input(\"User: \")\n",
        "  while not user_prompt.lower() == 'end':\n",
        "    response = user_chat.ask(user_prompt)\n",
        "    print(\"Professor:\", response)\n",
        "    user_prompt = input(\"User: \")\n",
        "    if user_prompt.lower() == 'new':\n",
        "      user_chat = Chat()\n",
        "      user_prompt = input(\"User: \")"
      ],
      "metadata": {
        "id": "UdsfPKpBbpQ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "simulate_chat()"
      ],
      "metadata": {
        "id": "GmNq1n3Fkxc3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-ea-IjV6qQIk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}